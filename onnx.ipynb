{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd0489d1f38f49522060cb8803dd9bf76741f00d22599df6f1d6212d7d413b77b3d",
   "display_name": "Python 3.8.8  ('env': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "489d1f38f49522060cb8803dd9bf76741f00d22599df6f1d6212d7d413b77b3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants.tf import my_pic\n",
    "import numpy as np\n",
    "import onnxruntime as rt\n",
    "import os\n",
    "from os import path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Lambda\n",
    "from tensorflow.keras import Model, Sequential, losses\n",
    "import tf2onnx.convert\n",
    "from typing import Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "random_state = 112\n",
    "tf.random.set_seed(random_state)\n",
    "\n",
    "# load data\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "# output path\n",
    "base_output_path = './out/models'\n",
    "h5_path = path.join(base_output_path, 'fashion_mnist_simple.h5')\n",
    "default_path = path.join(base_output_path, 'fashion_mnist_simple')\n",
    "onnx_path = path.join(base_output_path, 'fashion_mnist_simple_tf_api.onnx')\n",
    "\n",
    "# set number of threads used\n",
    "tf.config.threading.set_intra_op_parallelism_threads(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(np_array: np.ndarray) -> np.ndarray:\n",
    "    flatten_array = []\n",
    "    for image in np_array:\n",
    "        flatten_array.append(image.flatten())\n",
    "    return np.array(flatten_array)\n",
    "\n",
    "\n",
    "def prepare_dir(dir_: str):\n",
    "    if not path.isdir(dir_):\n",
    "        os.makedirs(dir_)\n",
    "\n",
    "\n",
    "train_set: Tuple[np.ndarray, np.ndarray]\n",
    "x_test: np.ndarray\n",
    "y_test: np.ndarray\n",
    "x_train: np.ndarray\n",
    "y_train: np.ndarray\n",
    "x_val: np.ndarray\n",
    "y_val: np.ndarray\n",
    "\n",
    "prepare_dir(base_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, (x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_val, y_train, y_val = train_test_split(\n",
    "    train_set[0], train_set[1], test_size=0.2, random_state=random_state)\n",
    "\n",
    "x_train = flatten(x_train)\n",
    "x_val = flatten(x_val)\n",
    "x_test = flatten(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x: np.ndarray, y: np.ndarray) -> Model:\n",
    "    model = Sequential([\n",
    "        Lambda(lambda x: x / 255, input_shape=(784,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        loss=loss, metrics=['accuracy'], optimizer='adam')\n",
    "    model.fit(x, y, epochs=10)\n",
    "    return model\n",
    "\n",
    "\n",
    "def predict(model: Model, x: np.ndarray, y: np.ndarray):\n",
    "    loss, acc = model.evaluate(x, y, verbose=2)\n",
    "\n",
    "\n",
    "def save_onnx(model: Model):\n",
    "    input_spec = (tf.TensorSpec((1, 784), tf.uint8, name='input'),)\n",
    "    tf2onnx.convert.from_keras(model, input_spec, output_path=onnx_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.6486 - accuracy: 0.7723\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3929 - accuracy: 0.8541\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3407 - accuracy: 0.8706\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.3179 - accuracy: 0.8813\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2996 - accuracy: 0.8891\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.2794 - accuracy: 0.8944\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2699 - accuracy: 0.8970\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2597 - accuracy: 0.9023\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2405 - accuracy: 0.9097\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2313 - accuracy: 0.9112\n",
      "313/313 - 1s - loss: 0.3339 - accuracy: 0.8834\n",
      "INFO:tensorflow:Assets written to: ./out/models/fashion_mnist_simple/assets\n",
      "WARNING:tensorflow:From /home/wvjgsuhp/sandbox/py/misc/env/lib/python3.8/site-packages/tf2onnx/tf_loader.py:557: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    }
   ],
   "source": [
    "model = train(x_train, y_train)\n",
    "predict(model, x_test, y_test)\n",
    "\n",
    "model.save(default_path)\n",
    "# h5\n",
    "model.save(h5_path)\n",
    "\n",
    "# onnx\n",
    "save_onnx(model)"
   ]
  },
  {
   "source": [
    "# H5 Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[4.5130808e-05 6.1313066e-11 1.3544183e-06 9.0103133e-11 1.6931474e-04\n  6.5114526e-13 9.9978429e-01 1.6953788e-15 1.5980359e-10 1.8996461e-16]] 6\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/CPU:0'):\n",
    "    model_h5 = tf.keras.models.load_model(h5_path)\n",
    "\n",
    "    prediction_h5 = model_h5.predict([my_pic])\n",
    "    print(prediction_h5, np.argmax(prediction_h5[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "113 ms ± 6.62 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit with tf.device('/CPU:0'): model_h5.predict([my_pic])"
   ]
  },
  {
   "source": [
    "# ONNX Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[array([[4.5130761e-05, 6.1312941e-11, 1.3544180e-06, 9.0102786e-11,\n        1.6931487e-04, 6.5114651e-13, 9.9978417e-01, 1.6953850e-15,\n        1.5980386e-10, 1.8996458e-16]], dtype=float32)] 6\n"
     ]
    }
   ],
   "source": [
    "sess = rt.InferenceSession(onnx_path)\n",
    "\n",
    "# set number of threads\n",
    "sess_options = sess.get_session_options()\n",
    "sess_options.intra_op_num_threads = 2\n",
    "\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "\n",
    "prediction_onnx = sess.run([output_name], {input_name: [my_pic]})\n",
    "print(prediction_onnx, np.argmax(prediction_onnx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "197 µs ± 10.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sess.run([output_name], {input_name: [my_pic]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer\n",
    "# 0 T-shirt/top\n",
    "# 1 Trouser\n",
    "# 2 Pullover\n",
    "# 3 Dress\n",
    "# 4 Coat\n",
    "# 5 Sandal\n",
    "# 6 Shirt\n",
    "# 7 Sneaker\n",
    "# 8 Bag\n",
    "# 9 Ankle boot"
   ]
  },
  {
   "source": [
    "# Random Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "47.5 µs ± 3.96 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.random.randint(0, 255, [1, 784], np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "101 µs ± 13.2 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sess.run([output_name], {input_name: np.random.randint(0, 255, [1, 784], np.uint8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit with tf.device('/CPU:0'): model_h5.predict(np.random.randint(0, 255, [1, 784], np.uint8))"
   ]
  }
 ]
}